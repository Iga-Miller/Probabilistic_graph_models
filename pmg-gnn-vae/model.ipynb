{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10, MNIST, CIFAR100\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza modelu\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VAE(nn.Module):\n",
    "#     def __init__(self, encoder, decoder, prior, L=16):\n",
    "#         super(VAE, self).__init__()\n",
    "\n",
    "#         self.encoder = encoder\n",
    "#         self.decoder = decoder\n",
    "#         self.prior = prior\n",
    "#         self.qz = None\n",
    "    \n",
    "#     def forward(self, x, reduction='avg'):\n",
    "#         x = x.view(x.shape[0], -1)\n",
    "#         mu_e, log_var_e = self.encoder.encode(x)\n",
    "#         z = self.encoder.sample(mu_e=mu_e, log_var_e=torch.exp(log_var_e))\n",
    "        \n",
    "#         # ELBO\n",
    "#         RE = self.decoder.log_prob(x, z)\n",
    "#         if self.prior == 'normal':\n",
    "#             self.qz = torch.distributions.Normal(mu_e, torch.exp(log_var_e))\n",
    "#             KL = torch.distributions.kl_divergence(self.qz, torch.distributions.Normal(0, 1)).sum(-1).mean()\n",
    "#         else:\n",
    "#             KL = (self.prior.log_prob(z) - self.encoder.log_prob(mu_e=mu_e, log_var_e=torch.exp(log_var_e), z=z)).sum(-1)\n",
    "\n",
    "        \n",
    "#         error = 0\n",
    "#         if np.isnan(RE.detach().numpy()).any():\n",
    "#             print('RE {}'.format(RE))\n",
    "#             error = 1\n",
    "#         if np.isnan(KL.detach().numpy()).any():\n",
    "#             print('KL {}'.format(KL))\n",
    "#             error = 1\n",
    "\n",
    "#         if error == 1:\n",
    "#             raise ValueError()\n",
    "\n",
    "#         if reduction == 'sum':\n",
    "#             return -(RE + KL).sum()\n",
    "#         else:\n",
    "#             return -(RE + KL).mean()\n",
    "\n",
    "#     def sample(self, batch_size=64):\n",
    "#         if self.prior == 'normal':\n",
    "#             z = self.qz.sample()\n",
    "#         else:\n",
    "#             z = self.prior.sample(batch_size=batch_size)\n",
    "#         return self.decoder.sample(z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class GMMPrior(nn.Module):\n",
    "#     def __init__(self, L, num_components):\n",
    "#         super(GMMPrior, self).__init__()\n",
    "\n",
    "#         self.L = L\n",
    "#         self.num_components = num_components\n",
    "\n",
    "#         # params\n",
    "#         self.means = nn.Parameter(torch.randn(num_components, self.L)*32)\n",
    "#         self.logvars = nn.Parameter(torch.randn(num_components, self.L))\n",
    "\n",
    "#         # mixing weights\n",
    "#         self.w = nn.Parameter(torch.zeros(num_components, 1, 1))\n",
    "\n",
    "#     def get_params(self):\n",
    "#         return self.means, self.logvars\n",
    "\n",
    "#     def sample(self, batch_size):\n",
    "#         # mu, lof_var\n",
    "#         means, logvars = self.get_params()\n",
    "\n",
    "#         # mixing probabilities\n",
    "#         w = F.softmax(self.w, dim=0)\n",
    "#         w = w.squeeze()\n",
    "\n",
    "#         # pick components\n",
    "#         indexes = torch.multinomial(w, batch_size, replacement=True)\n",
    "\n",
    "#         # means and logvars\n",
    "#         eps = torch.randn(batch_size, self.L)\n",
    "#         for i in range(batch_size):\n",
    "#             indx = indexes[i]\n",
    "#             if i == 0:\n",
    "#                 z = means[[indx]] + eps[[i]] * torch.exp(logvars[[indx]])\n",
    "#             else:\n",
    "#                 z = torch.cat((z, means[[indx]] + eps[[i]] * torch.exp(logvars[[indx]])), 0)\n",
    "#         return z\n",
    "\n",
    "#     def log_prob(self, z):\n",
    "#         # mu, lof_var\n",
    "#         means, logvars = self.get_params()\n",
    "\n",
    "#         # mixing probabilities\n",
    "#         w = F.softmax(self.w, dim=0)\n",
    "\n",
    "#         # log-mixture-of-Gaussians\n",
    "#         z = z.unsqueeze(0) # 1 x B x L\n",
    "#         means = means.unsqueeze(1) # K x 1 x L\n",
    "#         logvars = logvars.unsqueeze(1) # K x 1 x L\n",
    "#         log_p = log_normal_diag(z, means, logvars) + torch.log(w) # K x B x L\n",
    "#         log_prob = torch.logsumexp(log_p, dim=0, keepdim=False) # B x L\n",
    "\n",
    "#         return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "#     # EVALUATION\n",
    "#     if model_best is None:\n",
    "#         # load best performing model\n",
    "#         model_best = torch.load(name + '.model')\n",
    "\n",
    "#     model_best.eval()\n",
    "#     loss = 0.\n",
    "#     N = 0.\n",
    "#     for _, test_batch in enumerate(test_loader):\n",
    "#         loss_t = model_best.forward(test_batch, reduction='sum')\n",
    "#         loss = loss + loss_t.item()\n",
    "#         N = N + test_batch.shape[0]\n",
    "#     loss = loss / N\n",
    "\n",
    "#     if epoch is None:\n",
    "#         print(f'FINAL LOSS: nll={loss}')\n",
    "#     else:\n",
    "#         print(f'Epoch: {epoch}, val nll={loss}')\n",
    "#     return loss\n",
    "\n",
    "\n",
    "\n",
    "# def samples_generated(name, data_loader, extra_name=''):\n",
    "#     x = next(iter(data_loader)).detach().numpy()\n",
    "\n",
    "#     # GENERATIONS-------\n",
    "#     model_best = torch.load(name + '.model')\n",
    "#     model_best.eval()\n",
    "\n",
    "#     num_x = 4\n",
    "#     num_y = 4\n",
    "#     x = model_best.sample(num_x * num_y)\n",
    "#     x = x.detach().numpy()\n",
    "\n",
    "#     fig, ax = plt.subplots(num_x, num_y)\n",
    "#     for i, ax in enumerate(ax.flatten()):\n",
    "#         plottable_image = np.reshape(x[i], (32, 32, 3))\n",
    "#         ax.imshow(plottable_image, cmap='gray')\n",
    "#         ax.axis('off')\n",
    "\n",
    "#     plt.savefig(name + '_generated_images' + extra_name + '.pdf', bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "# def tsne_plot(name, data_loader, extra_name=\"\"):\n",
    "#     x = next(iter(data_loader)).detach().numpy()\n",
    "\n",
    "#     # GENERATIONS-------\n",
    "#     model_best = torch.load(name + '.model')\n",
    "#     model_best.eval()\n",
    "\n",
    "#     num_x = 4\n",
    "#     num_y = 4\n",
    "#     x = model_best.sample(num_x * num_y)\n",
    "#     x = x.detach().numpy()\n",
    "#     model_tsne = TSNE(n_components=2, random_state=0, perplexity=5).fit_transform(x)\n",
    "#     fig = plt.figure()\n",
    "#     plt.scatter(model_tsne[:, 0], model_tsne[:, 1])\n",
    "#     plt.show()\n",
    "#     plt.savefig(name + '_tsne.pdf', bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "# def plot_curve(name, nll_val):\n",
    "#     plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
    "#     plt.xlabel('epochs')\n",
    "#     plt.ylabel('nll')\n",
    "#     plt.savefig(name + '_nll_val_curve.pdf', bbox_inches='tight')\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader):\n",
    "#     nll_val = []\n",
    "#     best_nll = 1000.\n",
    "#     patience = 0\n",
    "\n",
    "#     # Main loop\n",
    "#     for e in range(num_epochs):\n",
    "#         # TRAINING\n",
    "#         model.train()\n",
    "#         for _, batch in enumerate(training_loader):\n",
    "#             if hasattr(model, 'dequantization'):\n",
    "#                 if model.dequantization:\n",
    "#                     batch = batch + torch.rand(batch.shape)\n",
    "#             loss = model.forward(batch)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward(retain_graph=True)\n",
    "#             optimizer.step()\n",
    "\n",
    "#         # Validation\n",
    "#         loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
    "#         nll_val.append(loss_val)  # save for plotting\n",
    "\n",
    "#         if e == 0:\n",
    "#             print('saved!')\n",
    "#             torch.save(model, name + '.model')\n",
    "#             best_nll = loss_val\n",
    "#         else:\n",
    "#             if loss_val < best_nll:\n",
    "#                 print('saved!')\n",
    "#                 torch.save(model, name + '.model')\n",
    "#                 best_nll = loss_val\n",
    "#                 patience = 0\n",
    "\n",
    "#                 samples_generated(name, val_loader, extra_name=\"_epoch_\" + str(e))\n",
    "#             else:\n",
    "#                 patience = patience + 1\n",
    "\n",
    "#         if patience > max_patience:\n",
    "#             break\n",
    "\n",
    "#     nll_val = np.asarray(nll_val)\n",
    "\n",
    "#     return nll_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = CIFAR10('./data', train=True, download=True)\n",
    "train_data, val_data = torch.utils.data.random_split(train.data.astype(float), [40000, 10000])\n",
    "test_data = CIFAR10('./data', train=False, download=True)\n",
    "\n",
    "# train = MNIST('./data', train=True, download=True)\n",
    "# train_data, val_data = torch.utils.data.random_split(train.data, [50000, 10000])\n",
    "# test_data = MNIST('./data', train=False, download=True)\n",
    "\n",
    "\n",
    "# train_data = Digits(mode='train')\n",
    "# val_data = Digits(mode='val')\n",
    "# test_data = Digits(mode='test')\n",
    "\n",
    "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.GMMPrior import GMMPrior\n",
    "from models.VAE import Encoder, Decoder, VAE\n",
    "from src.utils import training, plot_curve, tsne_plot\n",
    "num_components = 4**2\n",
    "\n",
    "lr = 1e-3\n",
    "num_epochs = 10\n",
    "max_patience = 5\n",
    "in_features = 32*32*3\n",
    "hid_dim=256\n",
    "lat_features = 12\n",
    "\n",
    "prior = GMMPrior(lat_features,num_components)\n",
    "encoder = Encoder(n_input_features=in_features, n_hidden_neurons=hid_dim, n_latent_features=lat_features)\n",
    "decoder = Decoder(n_hidden_neurons=hid_dim, n_latent_features=lat_features, n_output_features=in_features)\n",
    "vae = VAE(encoder=encoder, decoder=decoder, prior=prior)\n",
    "\n",
    "optimizer = torch.optim.Adamax(vae.parameters(), lr=lr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, val nll=-366694.4023953672\n",
      "saved!\n",
      "Epoch: 1, val nll=-366707.9186761355\n",
      "saved!\n",
      "Epoch: 2, val nll=-366714.83471198025\n",
      "saved!\n",
      "Epoch: 3, val nll=-366734.90125488775\n",
      "saved!\n",
      "Epoch: 4, val nll=-366739.1574045118\n",
      "saved!\n",
      "Epoch: 5, val nll=-366742.10397621564\n",
      "saved!\n",
      "Epoch: 6, val nll=-366744.3148308455\n",
      "saved!\n",
      "Epoch: 7, val nll=-366746.9396689731\n",
      "saved!\n",
      "Epoch: 8, val nll=-366747.89924804127\n",
      "saved!\n",
      "Epoch: 9, val nll=-366752.99693279364\n",
      "saved!\n"
     ]
    }
   ],
   "source": [
    "name = 'vae_' + \"GMM\" + '_' + str(num_components) + '_' + str(lat_features)+'_'+str(hid_dim)+'_'+str(max_patience)\n",
    "result_dir ='results/' + name + '/'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "\n",
    "nll_val = training(name=result_dir + name, max_patience=max_patience, num_epochs=num_epochs, model=vae, optimizer=optimizer,\n",
    "                       training_loader=training_loader, val_loader=val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve(nll_val=nll_val, name=result_dir+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsne_plot(result_dir + name, training_loader, \"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
